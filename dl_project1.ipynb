{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fcff262",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f81530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11527f8-e723-4a03-898d-7fa16c912863",
   "metadata": {},
   "source": [
    "## Load images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e58468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a folder and convert them to a tensor\n",
    "def load_images(folder_path):\n",
    "    images_paths = os.listdir(folder_path)\n",
    "    images = []\n",
    "    for filename in tqdm(images_paths, desc = \"Reading images\"):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "\n",
    "    images_tensor = torch.Tensor(images)\n",
    "    return images_tensor\n",
    "\n",
    "# Function to load CSV file and convert labels to a tensor\n",
    "def load_labels(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = df['Class'].values\n",
    "    labels_tensor = torch.Tensor(labels)\n",
    "    return labels_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59290a84-60d2-4852-a380-236826f8d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading images: 100%|██████████| 13000/13000 [00:14<00:00, 907.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Tensor Shape: torch.Size([13000, 64, 64, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aledragomir\\AppData\\Local\\Temp\\ipykernel_26780\\2685528804.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  images_tensor = torch.Tensor(images)\n"
     ]
    }
   ],
   "source": [
    "# Specify the paths\n",
    "train_images_folder_path = \"train_images\"\n",
    "\n",
    "# Load images and labels into tensors\n",
    "train_images = load_images(train_images_folder_path)\n",
    "\n",
    "# Print the shapes of the resulting tensors\n",
    "print(\"Images Tensor Shape:\", train_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b394fe-42bf-4af7-adf5-c5f8c051221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Tensor Shape: torch.Size([13000])\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"train.csv\"\n",
    "\n",
    "train_labels = load_labels(csv_path)\n",
    "\n",
    "print(\"Labels Tensor Shape:\", train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca0c7d5-d0c2-4edd-b023-b4fa27fc4b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aledragomir\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\aledragomir\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\aledragomir\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1638052 (6.25 MB)\n",
      "Trainable params: 1638052 (6.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def SimpleCNN():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten before fully connected layersa\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='softmax'))  # Output size is the number of classes\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79552ec-8a18-4d13-a691-98e1ac17849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have images_tensor and labels_tensor from previous steps\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert NumPy arrays to TensorFlow tensors\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# batch_size = 64\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162e2ec1-5d8e-432c-9988-b2f65dc39db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aledragomir\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Assuming labels are integers\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a28b36c-7daf-435b-a751-3b14d189bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\aledragomir\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\aledragomir\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "325/325 [==============================] - 25s 73ms/step - loss: 6.8620 - accuracy: 0.0079 - val_loss: 4.6089 - val_accuracy: 0.0081\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 4.5464 - accuracy: 0.0248 - val_loss: 4.6422 - val_accuracy: 0.0069\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 21s 65ms/step - loss: 4.2308 - accuracy: 0.0844 - val_loss: 4.9469 - val_accuracy: 0.0092\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 3.6482 - accuracy: 0.2062 - val_loss: 5.9100 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 21s 64ms/step - loss: 2.9824 - accuracy: 0.3438 - val_loss: 6.9850 - val_accuracy: 0.0104\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 21s 65ms/step - loss: 2.4620 - accuracy: 0.4594 - val_loss: 9.1809 - val_accuracy: 0.0096\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 2.1703 - accuracy: 0.5250 - val_loss: 10.7736 - val_accuracy: 0.0104\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 21s 66ms/step - loss: 1.8472 - accuracy: 0.5966 - val_loss: 12.3290 - val_accuracy: 0.0123\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 21s 64ms/step - loss: 1.5623 - accuracy: 0.6523 - val_loss: 15.1536 - val_accuracy: 0.0088\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 22s 66ms/step - loss: 1.3740 - accuracy: 0.7030 - val_loss: 17.7670 - val_accuracy: 0.0115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1534ccaa390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model[0].parameters(), lr=0.001)\n",
    "\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=10, validation_data=(X_test_tensor, y_test_tensor))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
